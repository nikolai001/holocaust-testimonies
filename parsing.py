# Code for parsing the dataimport osfrom bs4 import BeautifulSoupimport pandastestimonyData = []files = os.listdir("raw-data")ignoredFiles = ['.DS_Store']for file in files:    try:        if not file in ignoredFiles: # This is solely due to a mac quirck on my end for a file named .DS_Store which causes my program to error on my computer                        text = open('raw-data/'+file, encoding="utf-8").read() # Opening the file and reading it and getting the protocol below            protocol = BeautifulSoup(text,features="lxml")                        dataBoxes = protocol.findAll("div",attrs={"style":"background-color:#b19d82; border:1px solid #433a2b; width:265px; margin-left:7px; padding:5px; margin-bottom:20px; float:left;"})                    # Factoring in that there can be multiple metadata boxes in a protocol we do findAll            protocolId = ""            name = "null"            gender = "null"            birthPlace = "null"            birthDate = "null"            residence = "null"            occupation = "null"            concentration = "null"            ghetto = "null"            camps = "null"                        for box in dataBoxes:                # Looping through all of our databoxes and finding the fields in it                metaData = box.findAll("span")                  for index, data in enumerate(metaData): # I use enumerate because I need to have an index so I can easily select the value for a field                                        fieldData = data.text.strip()                    protocolId = protocol.find('h1').text.strip().split(' ')[-1] # Getting the protocol ID                                        if fieldData == "Name": # Checking the different properties metadata can contain i.e Name, gender etc etc                        name = metaData[index + 1].text.strip() # Getting the index of the current metadata field and iterating by 1 to get the value and stripping the data of any unnecesarry spaces etc                    elif fieldData == "Gender":                        gender = metaData[index + 1].text.strip()                    elif fieldData == "Place of birth":                        birthPlace = metaData[index + 1].text.strip()                    elif fieldData == "Date of birth":                        birthDate = metaData[index + 1].text.strip()                    elif fieldData == "Place of residence":                        residence = metaData[index + 1].text.strip()                    elif fieldData == "Occupation":                        occupation = metaData[index + 1].text.strip()                    elif fieldData == "Concentration":                        concentration = metaData[index + 1].text.strip()                    elif fieldData == "Ghetto":                        ghetto = metaData[index + 1].text.strip()                    elif fieldData == "Camps":                        camps = metaData[index + 1].text.strip()                                testimonyData.append([protocolId,name,gender,birthPlace,birthDate,residence,occupation,concentration,ghetto,camps]) # Appending the data from the loop                        fileName = protocol.find('h1').text.strip().replace(' ','_').replace('.','_').replace('__','_') # Getting the headline to use as the file name and making it pc naming friendly                        testimonyText = protocol.find('div', attrs={"id": "content"}) # Getting the content of the page wherein the text is kept                        removeStyle = "background-color:#b19d82; border:1px solid #433a2b; width:265px; margin-left:7px; padding:5px; margin-bottom:20px; float:left;" # Pinpointing the styles we dont want                        removeMetas = testimonyText.find_all('div', style=removeStyle) # Removing metadata in this example            for removeMeta in removeMetas:                removeMeta.extract()                        removeHeadlines = testimonyText.find_all('h1') # Removing all headlines            for removeHeadline in removeHeadlines:                removeHeadline.extract()                        removeSpans = testimonyText.find_all('span') # Removing all spans            for removeSpan in removeSpans:                removeSpan.extract()                        f = open('testimonies/'+fileName+'.txt','w',encoding="utf-8")            f.write(str(testimonyText.text.strip())) # Saving all the testimonies from the raw data as txt files                except AttributeError:        print("Cannot parse page "+file)df = pandas.DataFrame(testimonyData,columns = ['protocol','name','gender','place_of_birth','date_of_birth','place_of_residence','occupation','concentration','ghetto','camps']) # Saving data to dataframedf.set_index('protocol',drop=True,inplace=True) # Making the index IDs the protocol IDs instead of 1,2,3 etcdf.to_csv('testimonies.csv', index=True, encoding='utf-8') # Creating CSV